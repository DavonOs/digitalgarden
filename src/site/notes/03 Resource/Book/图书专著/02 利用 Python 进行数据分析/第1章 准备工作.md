---
{"dg-publish":true,"dg-permalink":"books/36632126/Preliminaries","permalink":"/books/36632126/Preliminaries/","metatags":{"description":"本书第 1 版出版于 2012 年，彼时基于 Python 的开源数据分析库（例如 pandas）仍然是一个发展迅速的新事物，本书也成为该领域排名 No 1 的经典畅销书，前两版中文版累计销售近 30 万册。第 3 版针对 Python 3.10 和 pandas 1.4 进行了更新，并通过实操讲解和实际案例向读者展示了如何高效地解决一系列数据分析问题。读者将在阅读过程中学习新版本的 pandas、NumPy、IPython 和 Jupyter。本书作者 Wes McKinney 是 Python pandas 项目的创始人。本书对 Python 数据科学工具的介绍既贴近实战又内容新颖，非常适合刚开始学习 Python 的数据分析师或刚开始学习数据科学和科学计算的 Python 程序员阅读。","og:site_name":"DavonOs","og:title":"利用 Python 进行数据分析 (原书第3版)","og:type":"book","og:url":"https://zuji.eu.org/books/36632126/Preliminaries","og:image":"https://i-blog.csdnimg.cn/direct/a3631c7292b546cc8982429c96df4bb4.png","og:image:width":"50","og:image:alt":"bookcover"},"tags":["program/python"],"dgShowInlineTitle":true,"created":"2025-09-15 16:42","updated":"2025-09-17 15:19"}
---

## 1.2 为什么使用 Python 进行数据分析

Python 语言极具吸引力。自从 1991 年诞生以来，Python 如今已经成为最受欢迎的解释型编程语言，其他的解释型语言包括 Perl、Ruby 等。自 2005 年起，由于拥有大量的 Web 框架（例如 Ruby 的 Rails 和 Python 的 Django），使用 Python 和 Ruby 构建网站变得尤为流行。这些语言常被称作脚本语言，因为它们可以用于编写简短的程序代码，或者编写自动化控制其他任务的脚本。但我个人并不喜欢“脚本语言”这个词，因为它的潜在意思好像是说这些语言无法用于构建正规的大型软件。在众多解释型语言中，由于各种历史和文化原因，Python 孕育了一个庞大而活跃的科学计算和数据分析社区。在过去的 20 年间，Python 从一门边缘或“自担风险”的科学计算语言成长为学界和工业界数据科学、机器学习、软件开发最重要的语言之一。

在数据分析、交互式计算以及数据可视化方面，Python 不可避免地与其他开源和商业领域的特定编程语言和工具进行对比，例如 R、MATLAB、SAS、Stata 等。由于近年来 Python 的库（例如 pandas 和 scikit-learn）不断得到优化，越来越多的人使用 Python 进行数据分析。再加上 Python 在通用编程方面的强大能力，它已成为构建数据应用的优选方案。

### Python 作为胶水语言

Python 在科学计算领域的成功，部分得益于它能够轻松集成 C、C++ 以及 Fortran 代码。大部分现代计算环境都利用了一些 Fortran 和 C 库来实现线性代数运算、最优化、积分、快速傅里叶变换以及其他诸如此类的算法。许多企业和国家实验室也利用 Python 来“黏合”那些已经用了数十年的遗留软件。

大多数软件都是由两部分代码组成的，一小部分需要占用大部分执行时间的代码，以及大部分不经常执行的“胶水代码”。在许多情况下，胶水代码的执行时间都是微不足道的。开发人员的精力几乎都花在优化计算瓶颈上，有时更需要转换为底层的语言（比如 C 语言）。

### 解决“双语”问题

通常，很多机构都会使用专业领域的计算语言（如 SAS 和 R）针对新想法做研究、构建原型和测试，然后再将这些想法移植到规模更大的生产系统中（可能是用 Java、C# 或 C++ 编写的）。人们逐渐意识到，Python 不仅适用于研究和构建原型，也适用于构建生产系统。既然一种语言就足够了，还有必要维持两套开发环境吗？我相信越来越多的企业会统一开发环境，因为研究人员和软件工程师使用同一套编程工具将会给企业带来非常显著的组织效益。

在过去的十年间，涌现出一批解决“双语”问题的新途径，例如 Julia 编程语言。在许多场景中，为了让 Python 物尽其用，需要用到 C 或 C++  等底层语言，然后将 Python 与其相连。尽管这样有些麻烦，但即时（Just-In-Time，JIT）编译技术能让人们不必脱离 Python 编程环境，使用像 Numba 这样的库，就能在许多算法中获得卓越的性能。

### 为何不使用 Python

虽然 Python 非常适合构建分析应用以及通用系统，但它对不少应用场景的适用性较差。

由于 Python 是解释型编程语言，因此通常大部分 Python 代码运行起来都要比用编译型语言（比如 Java 和 C++）编写的代码慢得多。由于程序员的时间通常都比 CPU 时间值钱，因此许多人也愿意对此做一些取舍。但是，在那些低延迟或高资源利用率的应用（例如高频交易系统）中，为了达到最高性能，花费时间使用诸如 C++这样底层（但生产效率更低）的语言进行编程也是值得的。

对于高并发、多线程的应用程序，尤其是拥有许多计算密集型线程的应用程序而言，Python 并不是一种理想的编程语言。这是因为 Python 有一个叫作全局解释器锁（Global Interpreter Lock，GIL）的组件，这是一种防止解释器同时执行多条 Python 字节码指令的机制。有关“为什么会存在 GIL”的技术性原因超出了本书的范围。虽然很多大数据处理应用程序为了能在较短的时间内完成数据集的处理工作都需要运行在计算机集群上，但是仍然有一些场景需要用单进程多线程系统来解决。

这并不是说 Python 不能执行真正的多线程并行代码。例如，Python 的 C 扩展使用原生的 C 或 C++的多线程，可以并行运行而不被 GIL 影响，只要它们不需要频繁地与 Python 对象交互。

## 1.3 重要的 Python 库

考虑到有些读者还不太了解 Python 科学计算生态和本书用到的库，下面先对各个库做简要介绍。

### NumPy

[NumPy](https://numpy.org) 是 Numerical Python（数值 Python）的简称，长期以来都是 Python 科学计算的基础包。它提供了多种数据结构、算法以及大部分涉及 Python 数值计算所需的接口。NumPy 还提供以下功能：
- 快速、高效的多维数组对象 ndarray。
- 用于对数组执行元素级计算以及直接对数组执行数学运算的函数。
- 用于读写硬盘上基于数组的数据集的工具。
- 线性代数运算、傅里叶变换，以及随机数生成。
- 成熟的 C API，用于 Python 扩展和原生 C、C++代码存取 NumPy 的数据结构和计算工具。

除了为 Python 提供快速的数组处理能力外，NumPy 在数据分析方面还有另外一个主要作用，即作为在算法和库之间传递数据的容器。对于数值型数据，NumPy 数组在存储和处理数据时要比内置的 Python 数据结构高效得多。此外，由底层语言（比如 C 和 Fortran）编写的库可以直接操作 NumPy 数组中的数据，无须将数据复制到其他内存中后再操作。因此，许多 Python 的数值计算工具要么使用 NumPy 数组作为主要的数据结构，要么可以与 NumPy 进行无缝交互操作。

### pandas

[pandas](https://pandas.pydata.org) 提供了快速便捷地处理结构化或表格型数据的高级数据结构和函数。自从 2010 年出现以来，它助力 Python 成为强大且高效的数据分析环境。本书中应用最多的 pandas 对象是 DataFrame，这是面向列的表格型数据结构，既有行标签也有列标签。另一个数据结构是 Series，它是一维的标签化数组对象。

pandas 兼具 NumPy 的高性能数组计算能力以及表格和关系型数据库（例如 SQL）的灵活数据操作功能。它提供了便捷的索引功能，可以完成重塑、切片、切块、连接和读取数据子集等操作。因为数据操作、预处理、清洗是数据分析中最重要的技能，所以 pandas 是本书的重点之一。

我是在 2008 年年初着手开发 pandas 的，那时我任职于 AQB Capital Management，这是一家量化投资管理公司。我那时有许多特殊工作需求都不能用任何单一工具解决，包括：

- 带有标签轴的数据结构，支持自动或清晰的数据对齐，以防止由于数据未对齐，以及处理不同数据源且不同索引的数据，而造成常见的错误。
- 集成时间序列功能。
- 用于同时处理时间序列数据和非时间序列数据的统一数据结构。
- 算术运算和可以保存元数据的约简操作。
- 灵活处理缺失数据。
- 合并和其他常见于流行数据库（例如基于 SQL 的数据库）的关系型操作。

我想只用一种工具就实现所有这些功能，最好还是用通用软件开发语言实现。Python 是一门不错的候选语言，但此时并没有集成的数据结构和工具来实现这些功能。因此我一开始就想把 pandas 设计为一款适用于金融和商业分析的工具，pandas 尤其擅长深度时间序列的功能和工具，非常适合商务处理中生成的时间索引数据。

2011 年和 2012 年，我和 AQR 的前同事 Adam Klein、Chang She 花费了大量时间拓展 pandas 的功能。2013 年，我暂停了日以继夜的项目开发工作，致力于让 pandas 变为完全社区拥有、社区维护的项目，此时社区中有超过 2000 名来自世界各地的开发贡献者。

对于使用 R 语言进行统计计算的用户，肯定不会对 DataFrame 这个名字感到陌生，因为它源自 R 的 data. frame 对象。但与 Python 不同，数据帧是内置于 R 语言及其标准库的。因此，pandas 的许多特点通常和 R 语言的核心实现或扩展包保持一致。

pandas 这个名字源于面板数据（计量经济学中针对多维结构化数据集的术语），同时也是 Python 数据分析（Python data analysis）的缩写。

### matplotlib

[matplotlib](https://matplotlib.org/) 是最流行的用于绘制图表和其他二维数据可视化的 Python 库。它最初由 John D. Hunter 创建，目前由一个庞大的开发团队维护。它非常适合创建出版物上使用的图表。虽然还有其他 Python 可视化库，但是 matplotlib 是使用最广泛的，并且它和其他生态工具配合也非常完美。我认为，可以使用 matplotlib 作为默认的可视化工具。

### IPython 和 Jupyter

[IPython 项目](https://ipython.org/)起初是 Fernando Pérez 在 2001 年创建的一个更具交互性的 Python 解释器的副产品。在随后的 20 年，它成为 Python 数据栈非常重要的工具之一。虽然 IPython 本身没有提供任何计算和数据分析的工具，但它可以大大提高交互式计算和软件开发的生产率。IPython 鼓励采用执行- 探索（execute- explore）的工作流，区别于其他编程软件的编辑- 编译- 运行（edit- compile- run）的工作流。它还可以方便地访问系统的命令行和文件系统，这样一来在许多场景中就无须在终端窗口和 Python 会话中来回切换。由于大部分数据分析编码包括探索、试错和重复迭代，因此 IPython 可以更快地完成工作。

2014 年，Fernando 和 IPython 团队宣布了 Jupyter 项目（https://jupyter.org/），旨在设计一个适用于更多语言的交互式计算工具。IPython Web notebook 则变成了 Jupyter notebook，现在支持 40 多种编程语言。IPython 现在可以作为内核（一种编程语言模式），用于在 Jupyter 中使用 Python。

IPython 自身变成了 Jupyter 庞大开源项目中的一个组件，Jupyter 是交互和探索式计算的高效环境。IPython 最古老、最简单的“模式”就是一个加强版的 Python 命令行终端，用于快速编写、测试、调试 Python 代码。你还可以在 Jupyter notebook 中使用 IPython。

Jupyter notebook 还可以编写 Markdown 和 HTML 文档，它提供了一种创建代码和文本的富文本方法。

我的大部分 Python 工作都要用到 IPython 和 Jupyter，包括运行、调试和测试代码。

### SciPy

[SciPy](https://scipy.org/) 是专门解决科学计算中多种基本问题的包的集合。以下是其中的一些模块：

`scipy.integrate`：数值积分例程和微分方程求解器。

`scipy.linalg`：扩展了由 numpy. linalg 提供的线性代数例程和矩阵分解功能。

`scipy.optimize`：函数优化器（最小化器）以及求根算法。

`scipy.signal`：信号处理工具。

`scipy.sparse`：稀疏矩阵和稀疏线性系统求解器。

`scipy.special`：SPECFUN 的封装器，SPECFUN 是一个实现了许多常用数学函数（例如，gamma 函数）的 FORTRAN 库。

`scipy.stats`：标准连续和离散概率分布（密度函数、采样器、连续分布函数）、各种统计检验方法，以及各类描述性统计。

结合使用 NumPy 和 SciPy，便形成了一个相当完备和成熟的计算平台，可以处理多种传统的科学计算问题。

### scikit-learn

自从 2007 年出现以来，[scikit-learn](https://scikit-learn.org/stable/) 就成为 Python 编程者首选的通用机器学习工具包。截至目前，有超过 2000 名开发者向 scikit-learn 贡献过代码。scikit-learn 包括以下子模块：

- 分类：支持向量机、最近邻、随机森林、逻辑回归等。
- 回归：Lasso 回归、岭回归等。
- 聚类：k 均值聚类、谱聚类等。
- 降维：主成分分析、特征选择、矩阵分解等。
- 模型选择：网格搜索、交叉验证、指标矩阵。
- 预处理：特征提取、正态化。

pandas、statsmodels、IPython 和 scikit-learn 对于 Python 成为高效数据科学编程语言起到了关键作用。虽然本书不会详细讲解 scikit-learn，但会简要介绍 scikit-learn 的一些模型，以及本书包含的其他工具如何使用这些模型。

### statsmodels

[statsmodels](https://www.statsmodels.org) 是一个统计分析包，源于斯坦福大学统计学教授 Jonathan Taylor，他设计了多种流行于 R 语言的回归分析模型。Skipper Seabold 和 Josef Perktold 在 2010 年正式创建了新的 statsmodels 项目，随后汇集了大量的使用者和贡献者。受到 R 语言公式系统的启发，Nathaniel Smith 开发了 Patsy 项目，提供了 statsmodels 的公式或模型的规范框架。

与 scikit-learn 相比，statsmodels 包含经典统计学（主要是频度）和计量经济学的算法。它包括如下子模块：

- 回归模型：线性回归、广义线性模型、鲁棒线性模型、线性混合效应模型等。
- 方差分析（ANalysis Of Variance，ANOVA）。
- 时间序列分析：AR、ARMA、ARIMA、VAR 等模型。
- 非参数方法：核密度估计、核回归。
- 统计模型结果可视化。

statsmodels 更关注统计推断，提供不确定性估计和 p 值参数检验。相反，scikit-learn 更关注预测。

与 scikit-learn 一样，本书只简要介绍 statsmodels，以及 NumPy 和 pandas 如何使用它。

### 其他包

关于数据科学的书中可能会介绍许多其他的 Python 包，其中就有一些新的项目，比如 TensorFlow 或 PyTorch，它们在机器学习和人工智能领域非常流行。但既然现在已经有其他书专门介绍这些项目，建议用本书学好常用的 Python 数据规整操作，为学习 TensorFlow 或 PyTorch 打好基础。


## 1.5 社区和会议

除了网络搜索，各式各样的科学和数据相关的 Python 邮件列表是非常有帮助的，很容易得到回答。可以看看下列邮件列表：
- pydata：一个 Google 群组列表，用来回答 Python 数据分析和 pandas 的问题。
- pystatsmodels：用来回答 statsmodels 或 pandas 相关的问题。
- scikit-learn scikit-learn@python.org 和 Python 机器学习的邮件列表。
- numpy-discussion：用来回答和 NumPy 相关的问题。
- scipy-user：用来回答 SciPy 和 Python 科学计算的问题。

因为这些邮件列表的地址可能发生变化，所以有意没有给出 URL，读者可以很容易在网上搜索到。

世界各地每年会举办许多 Python 开发者大会，如果你想结识其他志趣相投的人，建议你尽量去参加。许多会议会对无力支付入场费和差旅费的人们提供经济支持。下面是一些会议：

- PyCon 和 EuroPython：北美和欧洲的两大主要 Python 会议；
- SciPy 和 EuroSciPy：北美和欧洲的两大面向科学计算的会议；
- PyData：世界范围内一系列的地区性会议，专注数据科学和数据分析用例；
- 国际和地区性的 PyCon 会议（参见http://pycon.org上的完整列表）。

## 1.6 本书导航

如果你之前从未使用过 Python，那你可能需要先阅读本书的第 2 章和第 3 章，我在这两章中简要介绍了 Python 的特点、IPython 命令行和 Jupyter notebook。

接下来，我简单介绍了 NumPy 的关键特性，附录 A 介绍了更高级的 NumPy 功能。然后，我介绍了 pandas，本书剩余的内容则聚焦于用 pandas、NumPy 和 matplotlib（用于可视化）处理数据分析问题。我已经尽量用循序渐进的方式串联全书知识，但偶尔会有章节之间的交叉，有时涉及的概念在之前没有介绍过。

尽管读者的最终工作目标不同，但任务大体可以分为以下几类：

与外部世界交互
读写各种格式的文件和数据存储。

数据准备
对数据进行清洗、整理、联合、正态化、重塑、切片、切块和转换，以进行分析。

数据转换
对多组数据集进行数学和统计操作，生成新的数据集（例如，通过分组参数连接成一个大表）。

建模和计算
将数据接入统计模型、机器学习算法或其他计算工具。

演示
创建交互式或静态的图形可视化或文本概述。

### 1.6.1 代码示例

本书大部分代码示例的输入形式和输出结果都会仿照其在 IPython 或 Jupyter notebook 中执行的样子进行排版：

CODE EXAMPLE
OUTPUT

当你看到类似的代码示例时，就是让你在编码环境中的 In 代码框输入代码，按回车键执行（Jupyter 中是按 Shift-Enter 键）。然后就可以在 Out 代码框看到输出结果。

为了提高本书的可读性和简洁性，我修改了默认的 NumPy 和 pandas 控制台输出设置。例如，你在数值数据中会看到更多的精度数字。为了完全匹配本书的输出结果，在运行代码示例之前，可以执行如下 Python 代码：

```python
import numpy as np
import pandas as pd
pd.options.display.max_columns = 20
pd.options.display.max_rows = 20
pd.options.display.max_colwidth = 80
np.set_printoptions(precision=4, suppress=True)
```

### 1.6.2 示例数据

各章示例的数据集都存放在 GitHub 仓库（https://github.com/wesm/pydata-book）中。如果无法访问 GitHub，请访问 Gitee 上的镜像地址（https://gitee.com/wesmckinn/pydata-book）。读者既可以使用 Git 版本控制命令行程序下载数据，也可以从网站的仓库下载数据的 zip 压缩包文件。如果遇到问题，可以到本书网站（https://wesmckinney.com/book）获取关于如何获得本书资料的最新指导。

如果读者下载好了包含示例数据集的 zip 文件，必须将压缩包完整解压到一个文件夹中。运行本书代码示例之前，还需要将终端路径切换到这个文件夹：

```bash
$pwd
/home/wesm/book-materials
$ls
appa.ipynb ch05. ipynb ch09. ipynb ch13. ipynb README.md
ch02. ipynb ch06. ipynb ch10. ipynb COPYING requirements.txt
ch03. ipynb ch07. ipynb ch11. ipynb datasets
ch04. ipynb ch08. ipynb ch12. ipynb examples
```

### 1.6.3 引用惯例

Python 社区已经广泛采取了一些常用模块的命名惯例：

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import statsmodels as sm
```

也就是说，当你看到 `np.arange` 时，它引用的是 NumPy 中的 arange 函数。之所以这么做，是因为在 Python 软件开发过程中从类似 NumPy 这种大型包一次性导入全部内容（` from numpy import *`）是一种不好的做法。