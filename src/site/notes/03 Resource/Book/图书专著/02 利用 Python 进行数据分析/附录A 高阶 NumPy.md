---
{"dg-publish":true,"dg-permalink":"books/36632126/Appendix-A—Advanced-NumPy","permalink":"/books/36632126/Appendix-A—Advanced-NumPy/","metatags":{"description":"本书第 1 版出版于 2012 年，彼时基于 Python 的开源数据分析库（例如 pandas）仍然是一个发展迅速的新事物，本书也成为该领域排名 No 1 的经典畅销书，前两版中文版累计销售近 30 万册。第 3 版针对 Python 3.10 和 pandas 1.4 进行了更新，并通过实操讲解和实际案例向读者展示了如何高效地解决一系列数据分析问题。读者将在阅读过程中学习新版本的 pandas、NumPy、IPython 和 Jupyter。本书作者 Wes McKinney 是 Python pandas 项目的创始人。本书对 Python 数据科学工具的介绍既贴近实战又内容新颖，非常适合刚开始学习 Python 的数据分析师或刚开始学习数据科学和科学计算的 Python 程序员阅读。","og:site_name":"DavonOs","og:title":"利用 Python 进行数据分析 (原书第3版)","og:type":"book","og:url":"https://zuji.eu.org/books/36632126/Appendix-A—Advanced-NumPy","og:image":"https://i-blog.csdnimg.cn/direct/a3631c7292b546cc8982429c96df4bb4.png","og:image:width":"50","og:image:alt":"bookcover"},"tags":["program/python"],"dgShowInlineTitle":true,"created":"2025-09-16 07:12","updated":"2025-09-21 18:10"}
---

# A.1 ndarray 对象的内部机理

NumPy 的 ndarray 提供了一种将同构类型数据块（可以是连续的或步进的）解释为多维数组对象的方式。数据类型（dtype）决定了数据的解释方式，比如浮点数、整数、布尔值等类型。

ndarray 如此强大，部分原因是所有数组对象都是数据块的步进视图。例如，你可能想知道数组视图 arr[:: 2，:- 1]不复制任何数据的原因是什么。简单地说，ndarray 不只是一块内存和一个 dtype，它还有步进信息，这使得数组能以各种步幅在内存中移动。更准确地讲，ndarray 内部由以下内容组成：

·指向数据的指针，数据指内存或内存映射文件中的一块数据。

·数据类型（dtype），用于描述数组中固定大小的值单元格。

·表示数组形状的元组。

·步进元组，其中的整数是指为了前进到当前维度的下一个元素，需要“步进”的字节数。

图 A- 1 简单模拟了 ndarray 的内部结构。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/5bdf9688ebbd5a2303f6855722c0b088607624eaf2355d7cd7da926691bfec5e.jpg)  
图 A-1：NumPy 的 ndarray 对象

例如，一个  $10\times 5$  的数组，其形状为（10，5）：

np.ones ((10, 5)). shapeOut[12]: (10, 5)

一个典型的（C 顺序，稍后将详细讲解）  $3\times 4\times 5$  的 float 64（8 个字节）数组，其步长为（160，40，8）。知道步长非常有用，通常，在一个特定轴上的步长越大，沿这个轴进行计算的开销就越大：

np.ones ((3, 4, 5), dtype=np. float 64). strides  Out[13]: (160, 40, 8)

虽然 NumPy 用户很少会对数组的步进信息感兴趣，但它们却是构建“零复制”数组视图的重要因素。步进甚至可以是负数，这样会使数组在内存中后向移动，比如在切片 obj[::- 1]或 obj[:, ... - 1]中就是这样。

# NumPy 数据类型层级

你可能偶尔需要检查数组中所包含的是不是整数、浮点数、字符串或 Python 对象。因为浮点数的种类很多（从 float 16 到 float 128），检查数据类型是否在类型列表中会非常麻烦。幸运的是，数据类型有超类，比如 np. integer 和 np. floating，它们可以与 np. issubdtype 函数结合使用：

ints = np.ones (10, dtype=np. uint 16)  floats = np.ones (10, dtype=np. float 32)  np.issubdtype (ints. dtype, np. integer)  Out[16]: True  np.issubdtype (floats. dtype, np. floating)  Out[17]: True

调用数据类型的 mro 方法，可以查看该数据类型的所有父类：

np. float 64. mro ()  Out[18]:  [numpy. float 64, numpy. floating, numpy. inexact, numpy. number, numpy. generic, float, object]

得到：

np.issubdtype (ints. dtype, np. number)  Out[19]: True

某些数据类型的名称中有尾随下划线。这是为了避免 NumPy 数据类型和 Python 内置数据类型的变量名发生冲突。

大部分 NumPy 用户完全不需要了解这些知识，但是这些知识偶尔能派上用场。图 A- 2 说明了数据结构层次结构，以及父类和子类关系。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/0718a7377f843165ac8085da6a63cc63dff3da45628c47da6cf70f051958905b.jpg)  
图 A-2：NumPy 数据类型的类的层级关系

# A.2 高阶数组操作

除了花式索引、切片、布尔条件选取子集等操作，数组的操作方式还有很多。虽然 pandas 中的高级函数可以处理数据分析工作中的许多任务，但有时需要编写一些在现有的库中找不到的数据算法。

# A.2.1 重塑数组

多数情况下，无须复制任何数据，就能将数组从一个形状转换为另一个形状。只需向数组的实例方法 reshape 传入表示新形状的元组即可实现。例如，假设有一个一维数组，我们希望将其重新排列为一个矩阵（如图 A- 3 所示）

arr = np.arange (8)  arr  Out[21]: array ([0, 1, 2, 3, 4, 5, 6, 7])  arr.reshape ((4, 2))  Out[22]:  array ([[0, 1], [2, 3], [4, 5], [6, 7\|0, 1], [2, 3], [4, 5], [6, 7]])

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/5fa7d1b1513a5014ee4c3726af041db447deed3e0a8bea144f3940d141fb111d.jpg)

A 图 A- 3：按 C 顺序（按行）和按 Fortran 顺序（按列）进行重塑

# 也可以重塑多维数组：

arr.reshape ((4, 2)). reshape ((2, 4))  Out[23]:  array ([[0, 1, 2, 3], [4, 5, 6, 7\|0, 1, 2, 3], [4, 5, 6, 7]])

传入的形状维度中的一个值可以是- 1，它表示该维度的大小由数据本身推断而来：

arr = np.arange (15)  arr.reshape ((5, - 1))

Out[25]: array ([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14\|0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]])

数组的 shape 属性是一个元组，可以将其传给 reshape：

other_arr = np.ones ((3, 5))

other_arr. shape  Out[27]: (3, 5)

arr.reshape (other_arr. shape)  Out[28]:  array ([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14\|0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14]])

与 reshape 这种将一维数组转换为多维数组的运算过程相反的运算通常称为扁平化或散化：

In[29]: arr  $=$  np. arange（15). reshape（（5，3））

In[30]: arr Out[30]: array（[[0，1，2]， [3，4，5]， [6，7，8]， [9,10,11]， [12，13，14\|0，1，2]， [3，4，5]， [6，7，8]， [9,10,11]， [12，13，14]])

In[31]: arr. ravel（) Out[31]: array（[0，1，2，3，4，5，6，7，8，9，10，11，12，13，14]）

如果结果中的值在原始数组中是连续的，则 ravel 不会生成底层数值的副本。

flatten 方法类似于 ravel，只不过它总是返回数据的副本：

In[32]: arr.flatten () Out[32]: array（[0，1，2，3，4，5，6，7，8，9，10，11，12，13，14]）

数组可以被重塑或散化为不同的顺序。这对 NumPy 新用户是一个比较微妙的问题，下一节将专门讲解这个问题。

# A.2.2 C 顺序和 Fortran 顺序

NumPy 可以用不同的排布方式存储内存中的数据。默认情况下，NumPy 数组是按行优先顺序创建的。在空间方面，这意味着对于二维数组的数据，每行中的数据项存放在相邻内存位置上。另一种顺序是列优先顺序，它意味着每列中的数据项存放在相邻内存位置上。

行优先顺序和列优先顺序又分别称为 C 顺序和 Fortran 顺序。在 FORTRAN 77 语言中，矩阵全都是列优先顺序的。

像 reshape 和 reval 这样的函数，都可以接收一个 order 参数，用于表示在数组中使用数据的顺序。大多数情况下，可以设为'C'或'F'（还有'A'和'K'等不常用的选项；具体请参考 NumPy 文档，以及图 A- 3 对这些选项的说明）：

arr = np.arange (12). reshape ((3, 4))

arrOut[34]: array ([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11\|0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]])

arr.ravel () Out[35]: array ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])

arr.ravel ('F') Out[36]: array ([0, 4, 8, 1, 5, 9, 2, 6, 10, 3, 7, 11])

二维或更高维数组的重塑过程比较令人费解（如图 A- 3 所示）。C 顺序和 Fortran 顺序的关键区别就是维度的遍历顺序：

C/行优先顺序

先遍历更高的维度（例如，轴 1 比轴 0 优先处理）。

Fortran/列优先顺序

后遍历更高的维度（例如，轴 0 比轴 1 优先处理）。

# A.2.3 数组的拼接和拆分

numpy. concatenate 可以接收由数组组成的序列（如元组、列表等），并按指定轴将其拼接起来：

arr 1 = np.array ([[1, 2, 3], [4, 5, 6\|1, 2, 3], [4, 5, 6]]) arr 2 = np.array ([[7, 8, 9], [10, 11, 12\|7, 8, 9], [10, 11, 12]]) np.concatenate ([arr 1, arr 2], axis=0) Out[39]: array ([[1, 2, 3],

[4, 5, 6], [7, 8, 9], [10, 11, 12]])

np.concatenate ([arr 1, arr 2], axis=1) Out[40]: array ([[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12\|1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]])

对于常见的拼接操作，还可以使用更为便捷的函数，比如 vstack 和 hstack。之前的操作还可以这样表达：

In[41]: np. vstack（（arr 1，arr 2）） Out[41]: array（[[1，2，3]， [4，5，6]， [7，8，9]， [10,11,12\|1，2，3]， [4，5，6]， [7，8，9]， [10,11,12]])

In[42]: np. hstack（（arr 1，arr 2）） Out[42]: array（[[1，2，3，7，8，9]， [4，5，6,10,11,12\|1，2，3，7，8，9]， [4，5，6,10,11,12]])

与此相反，split 用于将数组沿指定轴拆分为多个数组：

In[43]: arr  $=$  rng. standard_normal ((5,2))

In[44]: arr Out[44]: array（[- 1.4238，1.2637]， [- 0.8707，- 0.2592]， [- 0.0753，- 0.7409]， [- 1.3678，0.6489]， [0.3611，- 1.9529]])

In[45]: first, second，third  $=$  np.split (arr，[1,3])

In[46]: first Out[46]:array（[[- 1.4238，1.2637\|- 1.4238，1.2637]])

In[47]: second Out[47]: array（[- 0.8707，- 0.2592]， [- 0.0753，- 0.7409]])

In[48]: third Out[48]: array（[[- 1.3678，0.6489]， [0.3611，- 1.9529\|- 1.3678，0.6489]， [0.3611，- 1.9529]])

传入 np. split 的值[1，3]表示在哪个索引位置分割数组。

表 A- 1 中列出了所有关于拼接和拆分的函数，其中一些仅作为通用 concatenate 的便捷方法。

表 A- 1：数组拼接和拆分函数

<table><tr><td>函数</td><td>说明</td></tr><tr><td>concatenate</td><td>最通用的函数，沿特定轴拼接数组集合</td></tr><tr><td>vstack、row_stack</td><td>按行堆叠数组（沿着轴 0）</td></tr><tr><td>hstack</td><td>按列堆叠数组（沿着轴 1）</td></tr><tr><td>column_stack</td><td>类似于 hstack，但是会先将一维数组转换为二维列向量</td></tr><tr><td>dstack</td><td>按“深度”堆叠数组（沿着轴 2）</td></tr><tr><td>split</td><td>沿指定轴，在传入的位置拆分数组</td></tr><tr><td>hsplit/vsplit</td><td>分别沿轴 0、轴 1 进行拆分的便捷函数</td></tr></table>

# 堆叠辅助方法：r_和 c_

NumPy 命名空间中有两个特殊的对象 r_和 c_，它们可以使数组的堆叠操作更简洁：

In[49]: arr  $=$  np. arange（6) In[50]: arr 1  $=$  arr.reshape ((3,2)) In[51]: arr 2  $=$  rng. standard_normal ((3,2)) In[52]: np. r_[arr 1, arr 2] Out[52]: array（[[0. ，1. ]， [2. ，3. ]， [4. ，5. ]， [2.3474，0.9685]， [- 0.7594，0.9022]， [- 0.467，- 0.0607\|0. ，1. ]， [2. ，3. ]， [4. ，5. ]， [2.3474，0.9685]， [- 0.7594，0.9022]， [- 0.467，- 0.0607]])

In[53]: np. c_[np. r_[arr 1, arr 2], arr] Out[53]: array（[[0. ，1. ，0. ]， [2. ，3. ，1. ]， [4. ，5. ，2. ]， [2.3474，0.9685，3. ]， [- 0.7594，0.9022，4. ]， [- 0.467，- 0.0607，5. \|0. ，1. ，0. ]， [2. ，3. ，1. ]， [4. ，5. ，2. ]， [2.3474，0.9685，3. ]， [- 0.7594，0.9022，4. ]， [- 0.467，- 0.0607，5. ]])

# 它们还可以将切片转换成数组：

In[54]: np. c_[1:6，- 10:- 5] Out[54]: array（[[1，- 10]， [2，- 9]， [3，- 8]， [4，- 7]， [5，- 6\|1，- 10]， [2，- 9]， [3，- 8]， [4，- 7]， [5，- 6]])

r_和 c_的具体功能请参考其文档字符串。

# A.2.4 元素的重复操作：tile 和 repeat

对数组进行重复操作或复制数组以生成更大数组的工具，主要是 repeat 和 tile 这两个函数。repeat 会将数组中的各个元素重复一定次数，从而产生一个更大的数组：

arr = np.arange (3)  arr  Out[56]: array ([0, 1, 2])  arr.repeat (3)  Out[57]: array ([0, 0, 0, 1, 1, 1, 2, 2, 2])

与其他流行的数组编程语言（如 MATLAB）不同，NumPy 中很少需要对数组进行复制或重复。这主要是因为广播机制能更好地满足该需求，我们将在下一节中讲解该技术。

默认情况下，如果传入的是一个整数，则各元素都会重复这么多次。如果传入的是整数数组，则各元素可以重复不同的次数：

arr.repeat ([2, 3, 4])  Out[58]: array ([0, 0, 1, 1, 1, 2, 2, 2, 2])

对于多维数组，还可以让它们的元素沿指定轴重复：

arr = rng. standard_normal ((2, 2))  arr  Out[60]:  array ([[ 0.7888, - 1.2567], [ 0.5759, 1.399 \| 0.7888, - 1.2567], [ 0.5759, 1.399 ]])  arr.repeat (2, axis=0)  Out[61]:  array ([[ 0.7888, - 1.2567], [ 0.7888, - 1.2567], [ 0.5759, 1.399 ], [ 0.5759, 1.399 \| 0.7888, - 1.2567], [ 0.7888, - 1.2567], [ 0.5759, 1.399 ], [ 0.5759, 1.399 ]])

注意，如果没有传入轴，则数组会先被扁平化，这可能不是想要的结果。类似地，在对多维数组进行重复时，也可以传入一个整数数组，这样就会使各切片重复不同的次数：

In[62]: arr. repeat（[2，3]，axis  $= 0$  一 Out[62]: array（[[0.7888，- 1.2567]， [0.7888，- 1.2567]， [0.5759，1.399]， [0.5759，1.399]， [0.5759，1.399\|0.7888，- 1.2567]， [0.7888，- 1.2567]， [0.5759，1.399]， [0.5759，1.399]， [0.5759，1.399]]) In[63]: arr. repeat（[2，3]，axis  $= 1$  一 Out[63]: array（[[0.7888，0.7888，- 1.2567，- 1.2567，- 1.2567]， [0.5759，0.5759，1.399，1.399，1.399\|0.7888，0.7888，- 1.2567，- 1.2567，- 1.2567]， [0.5759，0.5759，1.399，1.399，1.399]])

另一方面，tile 是一种沿指定轴向堆叠数组副本的快捷方法。你可以形象地将其想象成“铺瓷砖”：

In[64]: arrOut[64]:array（[[0.7888，- 1.2567]，[0.5759，1.399\|0.7888，- 1.2567]，[0.5759，1.399]]) In[65]: np.tile (arr, 2) Out[65]:array（[[0.7888，- 1.2567，0.7888，- 1.2567]，[0.5759，1.399，0.5759，1.399\|0.7888，- 1.2567，0.7888，- 1.2567]，[0.5759，1.399，0.5759，1.399]])

第二个参数是“瓷砖”的数量。对于标量，铺设是逐行进行的，而不是逐列的。tile 的第二个参数可以是表示“铺设”布局的元组：

In[66]: arrOut[66]:array（[[0.7888，- 1.2567]，[0.5759，1.399\|0.7888，- 1.2567]，[0.5759，1.399]]) In[67]: np.tile (arr，(2，1)) Out[67]:array（[[0.7888，- 1.2567]，[0.5759，1.399]，[0.7888，- 1.2567]，[0.5759，1.399\|0.7888，- 1.2567]，[0.5759，1.399]，[0.7888，- 1.2567]，[0.5759，1.399]]) In[68]: np.tile (arr，(3，2)) Out[68]:array（[[0.7888，- 1.2567，0.7888，- 1.2567]，[0.5759，1.399，0.5759，1.399]，[0.7888，- 1.2567，0.7888，- 1.2567]，[0.5759，1.399，0.5759，1.399]，[0.7888，- 1.2567，0.7888，- 1.2567]，[0.5

# A.2.5 花式索引的等价方法：take 和 put

第 4 章讲过，获取和设置数组子集的办法之一是通过整数数组使用花式索引：

arr  $=$  np. arange（10）\*100 inds  $=$  [7,1,2,6]arr[inds]Out[71]: array（[700，100，200，600]）

对于在单个轴向上进行选取这种特殊情况，ndarray 还有其他方法：

arr.take (inds) Out[72]: array（[700，100，200，600]） arr.put (inds, 42) arr Out[74]: array（[0，42，42,300,400,500，42，42,800,900]） arr.put (inds,[40,41,42,43]) arr Out[76]: array（[0，41，42,300,400,500，43，40,800,900]）

要在其他轴上使用 take，只需传入关键字 axis 即可：

inds  $=$  [2,0,2,1] arr  $=$  rng. standard_normal ((2,4)) arr Out[79]: array（[[1.3223，- 0.2997，0.9029，- 1.6216]， [- 0.1582，0.4495，- 1.3436，- 0.0817\|1.3223，- 0.2997，0.9029，- 1.6216]， [- 0.1582，0.4495，- 1.3436，- 0.0817]]） arr.take (inds, axis  $\mathbf{\dot{\tau}} = \mathbf{1}$  一 Out[80]: array（[[0.9029，1.3223，0.9029，- 0.2997]， [- 1.3436，- 0.1582，- 1.3436，0.4495\|0.9029，1.3223，0.9029，- 0.2997]， [- 1.3436，- 0.1582，- 1.3436，0.4495]]）

put 不接收参数 axis，它只会在数组的扁平化（一维，C 顺序）版本上进行索引。因此，在需要用其他轴向的索引设置元素时，最好还是使用花式索引。

# A.3 广播

广播机制指的是不同形状数组之间的算术运算执行方式。这是一种非常强大的功能，但也容易令人误解，即使是经验丰富的老手也是如此。标量值和数组的运算是最简单的广播示例：

arr = np.arange (5) arrOut[82]: array ([0, 1, 2, 3, 4]) arr * 4 Out[83]: array ([0, 4, 8, 12, 16])

在这个乘法运算中，标量值 4 被广播到了其他所有元素上。

看一个例子，我们可以通过减去列平均值的方式，降低数组中每一列的数值。对于这种情况，只能通过减去包含各列平均值的数组来实现：

arr = rng. standard_normal ((4, 3)) arr.mean (0) Out[85]: array ([0.1206, 0.243, 0.1444]) demeaned = arr - arr.mean (0) demeanedOut[87]: array ([[1.6042, 2.3751, 0.633], [0.7081, - 1.202, - 1.3538], [- 1.5329, 0.2985, 0.6076], [- 0.7793, - 1.4717, 0.1132\|1.6042, 2.3751, 0.633], [0.7081, - 1.202, - 1.3538], [- 1.5329, 0.2985, 0.6076], [- 0.7793, - 1.4717, 0.1132]]) demeaned.mean (0) Out[88]: array ([0., - 0., 0. ]

图 A- 4 形象地展示了该操作过程。用广播的方式对行减去均值时需要特别留心。幸运的是，只要遵循一定的规则，低维度的值是可以被广播到数组的任意维度的（比如对二维数组各列减去行平均值）。

于是就得到了广播机制。

# 广播机制

如果两个数组的后缘维度（即从末尾开始算起的维度）的轴长度相符或其中一方的长度为 1，则这两个数组是广播兼容的。广播会在缺失维度或长度为 1 的维度上进行。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/41f4129dd3f868c8a680b0bc61269af83caddd91011bbd345f0c6efa6500af18.jpg)  
图 A-4：一维数组沿轴 0 进行广播

即使作为一名经验丰富的 NumPy 用户，我还是得经常停下来画张图并思考广播机制。再考虑一下刚刚的示例，假设我们希望对各行减去行平均值。由于 arr. mean（0）的长度为 3，因此它可以沿轴 0 进行广播。这是因为 arr 的后缘维度是 3，所以它们是兼容的。根据该机制，要在轴 1 上做减法（即各行减去行平均值），较小数组的形状必须是（4，1）：

In[89]: arrOut[89]:array（[[1.7247，2.6182，0.7774]，[0.8286，- 0.959，- 1.2094]，[- 1.4123，0.5415，0.7519]，[- 0.6588，- 1.2287，0.2576\|1.7247，2.6182，0.7774]，[0.8286，- 0.959，- 1.2094]，[- 1.4123，0.5415，0.7519]，[- 0.6588，- 1.2287，0.2576]]）

In[90]: row_means  $=$  arr. mean（1)

In[91]: row_means. shapeOut[91]:（4,)

In[92]: row_means.reshape ((4,1)) Out[92]:array（[[1.7068]，[- 0.4466]，[- 0.0396]，[- 0.5433\|1.7068]，[- 0.4466]，[- 0.0396]，[- 0.5433]])

In[93]: demeaned  $=$  arr - row_means.reshape ((4,1))

In[94]: demeaned. mean（1) Out[94]: array（[- 0. ，0. ，0. ，0. ]）

图 A- 5 说明了该运算的过程。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/a64ff0098ae8654ed55a9796672e87540e7b92f359229afbae6df0380266633d.jpg)  
图 A-5：二维数组沿轴 1 进行广播

图 A- 6 展示了另外一种情况，这次是在三维数组上沿轴 0 加上一个二维数组。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/8eae1e4c76a8daf549f448ce93ff79e405149b35361d0d424ebe8c99941fdafa.jpg)  
图 A-6：三维数组沿轴 0 进行广播

# A.3.1 沿其他轴向进行广播

高维度数组的广播似乎更令人费解，而实际上它也遵循广播机制。如果不遵守广播机制，就会得到下面这样的错误：

arr - arr.mean (1) ValueError Traceback (most recent call last) <ipython- input- 95- 8b8ada26fac0> in <module> - - - - > 1 arr - arr.mean (1) ValueError: operands could not be broadcast together with shapes (4,3) (4,)

人们经常需要通过算术运算过程，将较低维度的数组在除轴 0 以外的其他轴向上广播。

根据广播机制，较小数组的“广播维度”必须为 1。在这个行减去均值的示例中，这就意味着要将行的形状变为（4，1）而非（4，）：

arr - arr.mean (1). reshape ((4, 1))  Out[96]:  array ([[0.018, 0.9114, - 0.9294], [1.2752, - 0.5124, - 0.7628], [- 1.3727, 0.5811, 0.7915], [- 0.1155, - 0.6854, 0.8009\|0.018, 0.9114, - 0.9294], [1.2752, - 0.5124, - 0.7628], [- 1.3727, 0.5811, 0.7915], [- 0.1155, - 0.6854, 0.8009]])

对于三维的情况，在三维中的任何一维上广播其实就是将数据重塑为兼容的形状。图 A- 7 说明了要在三维数组各维度上进行广播的形状需求。

![](https://cdn-mineru.openxlab.org.cn/result/2025-09-15/af04d75d-9613-4dcf-a3e0-cf9b482a4413/7723854b4232c53394531e317532aca6919f90db3b35ab2988516f50cc0445c2.jpg)  
图 A-7：能在该三维数组上进行广播的二维数组的形状

于是就有了一个非常普遍的问题，即为了广播，需要专门添加一个长度为 1 的新轴。虽然 reshape 是一个办法，但插入轴需要构造一个表示新形状的元组。这通常是一个很郁闷的过程。因此，NumPy 数组提供了一种通过索引机制插入轴的特殊语法。下面这段代码通过特殊的 np. newaxis 属性以及“全”切片来插入新轴：

arr = np.zeros ((4, 4))  arr_3 d = arr[:, np. newaxis, :]  arr_3 d. shape  Out[99]: (4, 1, 4)  arr_1 d = rng. standard_normal (3)

arr_1 d[:, np. newaxis]Out[101]: array ([[0.3129],[- 0.1308],[1.27 \|0.3129],[- 0.1308],[1.27 ]]) arr_1 d[np. newaxis, :]Out[102]: array ([[0.3129, - 0.1308, 1.27 \|0.3129, - 0.1308, 1.27 ]])

因此，如果我们有一个三维数组，并希望对轴 2 减去均值，那么只需要编写以下代码即可：

arr  $=$  rng. standard_normal ((3，4，5)) depth_means  $=$  arr.mean (2) depth_means Out[105]: array（[[0.0431，0.2747，- 0.1885，- 0.2014]， [- 0.5732，- 0.5467，0.1183，- 0.6301]， [0.0972，0.5954，0.0331，- 0.6002\|0.0431，0.2747，- 0.1885，- 0.2014]， [- 0.5732，- 0.5467，0.1183，- 0.6301]， [0.0972，0.5954，0.0331，- 0.6002]]） depth_means. shape Out[106]：(3，4) demeaned  $=$  arr - depth_means[:,:, np. newaxis] demeaned.mean (2) Out[108]: array（[[0. ，- 0. ，0. ，- 0. ]， [0. ，- 0. ，- 0. ，- 0. ]， [0. ，0. ，0. ，0. \|0. ，- 0. ，0. ，- 0. ]， [0. ，- 0. ，- 0. ，- 0. ]， [0. ，0. ，0. ，0. ]])

有些读者可能会想，在对指定轴减去均值时，有没有一种既通用又不牺牲性能的方法呢？实际上是有的，但需要一些索引方面的技巧：

def demean_axis (arr, axis  $= 0$  ：means  $=$  arr.mean (axis) #将形如 [：，：，np. newaxis]的对象推广到 N 维 indexer  $=$  [slice (None)] \* arr. ndim indexer[axis]  $=$  np. newaxis return arr - means[indexer]

# A.3.2 通过广播设置数组的值

算术运算所遵循的广播机制同样也适用于通过数组索引设置数值。举一个简单的例子，我们可以这样做：

In[109]: arr = np.zeros ((4, 3))

In[110]: arr[:] = 5

In[111]: arrOut[111]: array ([[5. , 5. , 5. ], [5. , 5. , 5. ], [5. , 5. , 5. ], [5. , 5. , 5. \|5. , 5. , 5. ], [5. , 5. , 5. ], [5. , 5. , 5. ], [5. , 5. , 5. ]])

但是，如果想用一维的数值数组来设置目标数组的列，只要保证形状兼容就可以了：

In[112]: col = np.array ([1.28, - 0.42, 0.44, 1.6])

In[113]: arr[:] = col[:, np. newaxis]

In[114]: arr

Out[114]:

array ([[1.28, 1.28, 1.28], [- 0.42, - 0.42, - 0.42], [0.44, 0.44, 0.44], [1.6, 1.6, 1.6\|1.28, 1.28, 1.28], [- 0.42, - 0.42, - 0.42], [0.44, 0.44, 0.44], [1.6, 1.6, 1.6]])

In[115]: arr[:] = [[- 1.37], [0.509\|- 1.37], [0.509]]

In[116]: arr

Out[116]:

array ([[- 1.37, - 1.37, - 1.37], [0.509, 0.509, 0.509], [0.44, 0.44, 0.44], [1.6, 1.6, 1.6\|- 1.37, - 1.37, - 1.37], [0.509, 0.509, 0.509], [0.44, 0.44, 0.44], [1.6, 1.6, 1.6]])

# A.4 高阶 ufunc 应用

虽然许多 NumPy 用户只会用到通用函数所提供的快速元素级运算，但通用函数实际上还有一些高级用法能使我们无须循环就能编写更简洁的代码。

# A.4.1 ufunc 实例方法

NumPy 的各个二元 ufunc 都有一些用于执行特定向量化运算的特殊方法。表 A- 2 汇总了这些方法，下面我将通过几个具体的例子对它们进行说明。

reduce 接收一个数组，并通过一系列二元运算对其值进行聚合（可指明轴向）。例如，我们可以用 np. add. reduce 对数组中各个元素进行求和：

arr = np.arange (10)  np.add.reduce (arr)  Out[118]: 45

arr.sum ()  Out[119]: 45

起始值取决于 ufunc（例如，对于 add，就是 0）。如果传入了轴，约简运算就会沿该轴向执行。这就使你能用一种比较简洁的方式解决某些问题。在下面这个不太常见的例子中，我们用 np. logical_and 检查数组各行中的值是不是有序的：

my_rng = np. random. default_rng (12346) # 为了可以复现

arr = my_rng. standard_normal ((5, 5))

arr

Out[122]:

array（[[- 0.9039，0.1571，0.8976，- 0.7622，- 0.1763]，[0.053，- 1.6284，- 0.1775，1.9636，1.7813]，[- 0.8797，- 1.6985，- 1.8189，0.119，- 0.4441]，[0.7691，- 0.0343，0.3925，0.7589，- 0.0705]，[1.0498，1.0297，- 0.4201，0.7863，0.9612\|- 0.9039，0.1571，0.8976，- 0.7622，- 0.1763]，[0.053，- 1.6284，- 0.1775，1.9636，1.7813]，[- 0.8797，- 1.6985，- 1.8189，0.119，- 0.4441]，[0.7691，- 0.0343，0.3925，0.7589，- 0.0705]，[1.0498，1.0297，- 0.4201，0.7863，0.9612]]）

arr[: 2]. sort (1) # 对行排序

arr[:, - 1] < arr[:, 1:]

Out[124]:

array（[[True, True, True, True], [False, True, True, False], [True, True, True, True], [False, True, True, False], [True, True, True, True\|True, True, True, True], [False, True, True, False], [True, True, True, True], [False, True, True, False], [True, True, True, True]])

np. logical_and.reduce (arr[:, - 1] < arr[:, 1:], axis=1)  Out[125]: array ([True, False, True, False, True])

注意，logical_and. reduce 和 all 方法是等价的。

ufunc 的 accumulate 方法与 reduce 有关，类似于 cumsum 与 sum 的关系。它生成一个与中间“累计”值大小相同的数组：

arr = np.arange (15). reshape ((3, 5))

np.add.accumulate (arr, axis=1)  Out[127]:  array ([[0, 1, 3, 6, 10], [5, 11, 18, 26, 35], [10, 21, 33, 46, 60\|0, 1, 3, 6, 10], [5, 11, 18, 26, 35], [10, 21, 33, 46, 60]])

outer 用于计算两个数组之间成对的交叉乘积：

arr = np.arange (3). repeat ([1, 2, 2])

arrOut[129]: array ([0, 1, 1, 2, 2])

np.multiply.outer (arr, np.arange (5)) Out[130]: array ([[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 2, 4, 6, 8\|0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 2, 4, 6, 8]])

outer 输出结果的维度是两个输入数据的维度拼接之和：

outer 输出结果的维度是两个输入数据的维度拼接之和：x, y = rng. standard_normal ((3, 4)), rng. standard_normal (5) result = np.subtract.outer (x, y) result. shapeOut[133]: (3, 4, 5)

最后一个方法 reduceat 用于计算“局部约简”，其实就是一个对数据各切片进行聚合的分组运算。它接收一组用于指示如何对值进行拆分和聚合的“分箱边界”：

arr = np.arange (10) np.add.reduceat (arr, [0, 5, 8]) Out[135]: array ([10, 18, 17])

最终结果是在 arr[0:5]、arr[5:8]以及 arr[8:]上执行的约简（此处为求和）。与其他方法一样，这里也可以传入参数 axis：

arr = np.multiply.outer (np.arange (4), np.arange (5))

arrOut[137]: array ([[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12\|0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12]])

np.add.reduceat (arr, [0, 2, 4], axis=1) Out[138]: array ([[0, 0, 0], [1, 5, 4], [2, 10, 8], [3, 15, 12\|0, 0, 0], [1, 5, 4], [2, 10, 8], [3, 15, 12]])

表 A- 2 列出了部分 ufunc 方法。

# 表 A-2：部分 ufunc 方法

<table><tr><td>方法</td><td>说明</td></tr><tr><td>accumulate (x)</td><td>对值进行聚合，保留所有局部聚合结果</td></tr><tr><td>a t (x, i n d i c e s, b=None)</td><td>对指定索引位置的 x 就地执行运算。对于需要两个输入数组的 ufunc，参数 b 是第二个输入参数</td></tr><tr><td>reduce (x)</td><td>通过执行连续运算进行聚合</td></tr><tr><td>reduceat (x, bins)</td><td>“局部”约简或分组。约简数据的各个切片以创建聚合数组</td></tr><tr><td>outer (x, y)</td><td>将运算应用于 x 和 y 中的所有元素对。结果数组形状为x.shape + y.shape</td></tr></table>

# A.4.2 使用 Python 编写新 ufunc

有多种方法可以编写自己的 NumPyufunc。最常见的是使用 NumPy C API，但它超越了本书的范围。本节介绍纯粹的 Pythonufunc。

numpy. frompyfunc 接收一个 Python 函数，以及两个分别表示输入参数数量与输出参数数量的参数。例如，下面是一个能够实现元素级加法的简单函数：

def add_elements (x, y):    ...:: return x + yadd_them = np.frompyfunc (add_elements, 2, 1) add_them (np.arange (8), np.arange (8)) Out[141]: array ([0, 2, 4, 6, 8, 10, 12, 14], dtype=object)

用 frompyfunc 创建的函数总是返回 Python 对象数组，这一点很不方便。幸运的是，还有另一个函数 numpy. vectorize，它可以让你指定输出类型：

add_them = np.vectorize (add_elements, otypes=[np. float 64]) add_them (np.arange (8), np.arange (8)) Out[143]: array ([0., 2., 4., 6., 8., 10., 12., 14. ]

虽然这两个函数提供了一种创建 ufunc 型函数的手段，但它们都非常慢，这是因为它们在计算每个元素时都要执行一次 Python 函数调用，这就导致比 NumPy 的基于 C 的 ufunc 循环慢得多：

arr = rng. standard_normal (10000) %timeit add_them (arr, arr) 2.43 ms +- 30.5 us per loop (mean +- std. dev. of 7 runs, 100 loops each) %timeit np.add (arr, arr) 2.88 us +- 47.9 ns per loop (mean +- std. dev. of 7 runs, 100000 loops each)

后面会介绍使用 Numba 库（http://numba.pydata.org）创建 Python 的快速 ufunc。

# A.5 结构化数组和记录式数组

你可能已经注意到了，到目前为止我们所讨论的 ndarray 都是一种同构数据容器。也就是说，在它所表示的内存块中，各元素占用的字节数相同，字节数多少具体根据数据类型而定。从表面上看，它似乎不能用于表示异构数据或表格型的数据。结构化数组是一种特殊的 ndarray，其中的各个元素可以看作 C 语言中的结构体（这就是其“结构化”的名字由来）或带有多个命名字段的 SQL 表中的一行：

dtype  $=$  [('x', np. float 64), ('y', np. int 32)] sarr  $=$  np. array（[（1.5，6)，（np. pi，- 2)]，dtype=dtype) sarr Out[149]: array（[（1.5，6)，(3.1416，- 2)]，dtype=[（'x'，'<f 8'),（'y'，'<i 4')]）

定义结构化数据类型（请参考 NumPy 在线文档）的方式有很多。最典型的办法之一是用元组列表，元组的格式为（field_name，field_data_type）。这样，数组的元素就成了元组式的对象，该对象中各个元素可以像字典那样进行访问：

sarr[0] Out[150]: (1.5, 6) sarr[0]['y'] Out[151]: 6

字段名保存在 dtype. names 属性中。在访问结构化数组的某个字段时，返回的是该数据的步进视图，所以不会发生数据复制：

sarr['x'] Out[152]: array ([1.5, 3.1416])

# A.5.1 嵌套 dtype 和多维字段

在指定结构化数据类型时，你可以额外传入一个形状（可以是整数或元组）：

dtype  $=$  [('x', np. int 64, 3), ('y', np. int 32)] arr  $=$  np.zeros (4, dtype=dtype) arr Out[155]: array（[（[0，0，0]，0)，（[0，0，0]，0)，（[0，0，0]，0)，（[0，0，0]，0)]， dtype=[('x', '<i 8', (3,), ('y', '<i 4')])

在这种情况下，字段 x 所引用的是各记录中长度为 3 的数组：

arr[0]['x']  Out[156]: array ([0, 0, 0])

这样，访问 arr['x']即可得到一个二维数组，而不是之前示例中的一维数组：

arr['x']  Out[157]:  array ([[0, 0, 0],  [0, 0, 0],  [0, 0, 0],  [0, 0, 0\|0, 0, 0],  [0, 0, 0],  [0, 0, 0],  [0, 0, 0]])

这使你能用数组的单个内存块存放更复杂的嵌套结构。你还可以嵌套数据类型，创建更复杂的结构。下面是一个例子：

dtype  $=$  [('x'，['a'，'f 8'），（'b'，'f 4'）]，（'y'，np. int 32)]data  $=$  np. array（[（(1，2)，5)，((3，4)，6)]，dtype=dtype) data['x']Out[160]: array（[（1. ，2. ），（3. ，4. ）]，dtype=[('a'，'<f 8'），（'b'，'<f 4'）]）data['y']Out[161]: array ([5,6]，dtype=int 32) data['x'][ 'a']Out[162]: array ([1. ，3. ]）

pandas 的 DataFrame 不以同样的方式支持该功能，尽管它与分层索引很相似。

# A.5.2 为什么使用结构化数组

与 pandas 的 DataFrame 相比，NumPy 的结构化数组是一种相对较低级的工具。它提供了一种途径，用于将单个内存块解释为带有任意嵌套列的表格型结构。由于数组中的每个元素在内存中都被表示为固定的字节数，所以结构化数组能够提供非常快速且高效的磁盘数据读写（包括内存映射）、网络传输等功能。结构化数组中各个值的内存布局基于 C 语言中结构数据类型的二进制表示。

结构化数组的另一个常见用法，是将数据文件写成固定长度的记录式字节流，这是 C 和  $\mathtt{C + + }$  代码中常见的数据序列化手段，常见于业界的遗留系统。只要知道文件的格式（记录的大小和顺序、字节大小以及各元素的数据类型），就可以用 np. fromfile 将数据读入内存。这种专门的用法超出了本书的范围，知道存在这种用法就可以了。

# A.6 关于排序的更多内容

类似于 Python 的内置列表，ndarray 的 sort 实例方法也是就地排序，也就是说，重新排列数组内容并不会创建新数组：

arr = rng. standard_normal (6)  arr.sort ()  arr  Out[165]: array ([- 1.1553, - 0.9319, - 0.5218, - 0.4745, - 0.1649, 0.03 ]))

在对数组进行就地排序时要注意一点，如果数组是不同 ndarray 的视图，则原始数组将会被修改：

arr = rng. standard_normal ((3, 5))  arr  Out[167]:  array ([[- 1.1956, 0.4691, - 0.3598, 1.0359, 0.2267], [- 0.7448, - 0.5931, - 1.055, - 0.0683, 0.458], [- 0.07, 0.1462, - 0.9944, 1.1436, 0.5026\|- 1.1956, 0.4691, - 0.3598, 1.0359, 0.2267], [- 0.7448, - 0.5931, - 1.055, - 0.0683, 0.458], [- 0.07, 0.1462, - 0.9944, 1.1436, 0.5026]])  arr[:, 0]. sort () # Sort first column values in place  arr  Out[169]:  array ([[- 1.1956, 0.4691, - 0.3598, 1.0359, 0.2267], [- 0.7448, - 0.5931, - 1.055, - 0.0683, 0.458], [- 0.07, 0.1642, - 0.9944, 1.1436, 0.5026\|- 1.1956, 0.4691, - 0.3598, 1.0359, 0.2267], [- 0.7448, - 0.5931, - 1.055, - 0.0683, 0.458], [- 0.07, 0.1642, - 0.9944, 1.1436, 0.5026]])

相反，numpy. sort 会创建一个新的已排序的数组副本。另外，它所接收的参数（比如 kind）和 ndarray 的 sort 方法一样：

arr = rng. standard_normal (5)  arr  Out[171]: array ([0.8981, - 1.1704, - 0.2686, - 0.796, 1.4522])  np.sort (arr)  Out[172]: array ([- 1.1704, - 0.796, - 0.2686, 0.8981, 1.4522])  arr  Out[173]: array ([0.8981, - 1.1704, - 0.2686, - 0.796, 1.4522])

这两个排序方法都可以接收轴向参数，用于沿指定轴向对部分数据进行独立排序：

arr = rng. standard_normal ((3, 5))  arr

Out[175]: array（[[- 0.2535，2.1183，0.3634，- 0.6245，1.1279]， [1.6164，- 0.2287，- 0.6201，- 0.1143，- 1.2067]， [- 1.0872，- 2.1518，- 0.6287，- 1.3199，0.083 \|- 0.2535，2.1183，0.3634，- 0.6245，1.1279]， [1.6164，- 0.2287，- 0.6201，- 0.1143，- 1.2067]， [- 1.0872，- 2.1518，- 0.6287，- 1.3199，0.083 ]]）

In[176]: arr.sort (axis=1)

In[177]: arrOut[177]: array（[[- 0.6245，- 0.2535，0.3634，1.1279，2.1183]，[- 1.2067，- 0.6201，- 0.2287，- 0.1143，1.6164]，[- 2.1518，- 1.3199，- 1.0872，- 0.6287，0.083 \|- 0.6245，- 0.2535，0.3634，1.1279，2.1183]，[- 1.2067，- 0.6201，- 0.2287，- 0.1143，1.6164]，[- 2.1518，- 1.3199，- 1.0872，- 0.6287，0.083 ]]）

你可能注意到了，这两个排序方法都没有设置降序排列的选项。这在实践中是个问题，因为数组切片会产生视图，不会创建副本，也不需要任何其他的计算工作。许多 Python 用户都很熟悉一个有关列表的小技巧，values[::- 1]可以返回反序的列表。ndarray 也适用这个技巧：

In[178]: arr[:,::- 1]Out[178]:array（[2.1183，1.1279，0.3634，- 0.2535，- 0.6245]，[1.6164，- 0.1143，- 0.2287，- 0.6201，- 1.2067]，[0.083，- 0.6287，- 1.0872，- 1.3199，- 2.1518]]）

# A.6.1 间接排序：argsort 和 lexsort

在数据分析工作中，可能需要根据一个或多个键对数据集进行排序。例如，一个有关学生信息的数据表可能需要先按姓后按名进行排序。这就是一个间接排序的例子，如果你阅读过有关 pandas 的章节，那就已经见过不少高级例子了。给定一个或多个键（一个数值数组或多个数值数组），你希望得到一个由整数组成的索引数组（我亲切地称之为索引器），用这个索引数组对数据重新排序为指定顺序。argsort 和 numpy. lexsort 就是实现该功能的两个方法。下面是一个简单的例子：

In[179]: values  $=$  np.array ([5,0,1,3,2]) In[180]: indexer  $=$  values.argsort () In[181]: indexerOut[181]: array ([1,2,4,3,0]) In[182]: values[indexer]Out[182]: array ([0,1,2,3,5])

再看一个更复杂的例子，下面这段代码根据数组的第一行对其进行排序：

In[183]: arr  $=$  rng. standard_normal ((3,5))

In[184]: arr[0] = values

In[185]: arrOut[185]:array（[5. ，0. ，1. ，3. ，2. ]，[- 0.7503，- 2.1268，- 1.391，- 0.4922，0.4505]，[0.8926，- 1.0479，0.9553，0.2936，0.5379]]）

In[186]: arr[:, arr[0]. argsort ()]Out[186]:array（[0. ，1. ，2. ，3. ，5. ]，[- 2.1268，- 1.391，0.4505，- 0.4922，- 0.7503]，[- 1.0479，0.9553，0.5379，0.2936，0.8926]]）

lexsort 类似于 argsort，只不过它按照字母顺序对多个键数组执行间接排序。假设我们想对以姓和名标识的数据进行排序：

In[187]: first_name  $=$  np.array (['Bob'，'Jane'，'Steve'，'Bill'，'Barbara']) In[188]: last_name  $=$  np.array (['Jones'，'Arnold'，'Arnold'，'Jones'，'Walters']) In[189]: sorter  $=$  np.lexsort ((first_name, last_name)) In[190]: sorterOut[190]: array ([1,2,3,0,4]) In[191]: list (zip (last_name[sorter]，first_name[sorter])) Out[191]:['Arnold'，'Jane'), ('Arnold'，'Steve'), ('Jones'，'Bill'), ('Jones'，'Bob'), ('Walters'，'Barbara')]

刚开始使用 lexsort 的时候可能会比较困惑，这是因为用于排序的键的顺序是从最后传入的数组算起的。在这个例子中，last_name 是先于 first_name 使用的。

# A.6.2 其他排序算法

稳定排序算法会保持相等元素的相对位置。对于相对位置具有实际意义的间接排序而言，这一点非常重要：

In[192]: values  $=$  np.array (['2: first'，'2: second'，'1: first'，'1: second'，'1: third']) In[193]: key  $=$  np.array ([2,2,1,1,1]) In[194]: indexer  $=$  key.argsort (kind  $\equiv$  'mergesort') In[195]: indexer

Out[195]: array ([2, 3, 4, 0, 1])

values.take (indexer) Out[196]: array (['1: first', '1: second', '1: third', '2: first', '2: second'], dtype='<U 8')

归并排序（mergesort）是唯一的稳定排序，它具有 O（nlogn）的性能，但是其平均性能比默认的快速排序（quicksort）要差。表 A- 3 列出了可用的排序算法及其相关的性能指标（和性能保证）。大部分用户完全不需要考虑这些，但了解一下总是好的。

表 A-3：数组排序算法  

<table><tr><td>种类</td><td>速度</td><td>是否稳定</td><td>工作空间</td><td>最坏情况</td></tr><tr><td>& #x27 ; quicksort& #x27 ;</td><td>1</td><td>否</td><td>0</td><td>O (n^2)</td></tr><tr><td>& #x27 ; mergesort& #x27 ;</td><td>2</td><td>是</td><td>n/2</td><td>O (n log n)</td></tr><tr><td>& #x27 ; heapsort& #x27 ;</td><td>3</td><td>否</td><td>0</td><td>O (n log n)</td></tr></table>

# A.6.3 数组的部分排序

排序的目的之一是确定数组中最大或最小的元素。NumPy 有两个围绕第 k 个最小元素划分数组的快速方法，即 numpy. partition 和 np. argpartition:

rng = np. random. default rng (12345)  arr = rng. standard_normal (20)  arr  Out[199]:  array ([- 1.4238, 1.2637, - 0.8707, - 0.2592, - 0.0753, - 0.7409, - 1.3678, 0.6489, 0.3611, - 1.9529, 2.3474, 0.9685, - 0.7594, 0.9022, - 0.467, - 0.0607, 0.7888, - 1.2567, 0.5759, 1.399])  np.partition (arr, 3)  Out[200]:  array ([- 1.9529, - 1.4238, - 1.3678, - 1.2567, - 0.8707, - 0.7594, - 0.7409, - 0.0607, 0.3611, - 0.0753, - 0.2592, - 0.467, 0.5759, 0.9022, 0.9685, 0.6489, 0.7888, 1.2637, 1.399, 2.3474])

当调用 partition（arr，3）之后，结果中的前三个元素是最小的三个值，且没有特定的顺序。numpy. argpartition 与 numpy. argsort 相似，它返回的是将数据重排为等价顺序的索引：

indices = np.argpartition (arr, 3)

indices

Out[202]: array ([ 9, 0, 6, 17, 2, 12, 5, 15, 8, 4, 3, 14, 18, 13, 11, 7, 16, 1, 19, 10])

arr.take (Indices) Out[203]: array ([- 1.9529, - 1.4238, - 1.3678, - 1.2567, - 0.8707, - 0.7594, - 0.7409, - 0.0607, 0.3611, - 0.0753, - 0.2592, - 0.467, 0.5759, 0.9022, 0.9685, 0.6489, 0.7888, 1.2637, 1.399, 2.3474])

# A.6.4 numpy. searchsorted：在有序数组中查找元素

searchsorted 是在有序数组上执行二分查找的数组方法，它返回的是数组中的位置，将值插入该位置可以维持数组的有序性：

arr = np.array ([0, 1, 7, 12, 15]) arr.searchsorted (9) Out[205]: 3

你还可以传入一个数值数组，以得到一个索引数组：

arr.searchsorted ([0, 8, 11, 16]) Out[206]: array ([0, 3, 3, 5])

从上面的结果中可以看出，对于元素 0，searchsorted 会返回 0。这是因为该方法默认返回一组相等值的左侧索引：

arr = np.array ([0, 0, 0, 1, 1, 1, 1]) arr.searchsorted ([0, 1]) Out[208]: array ([0, 3]) arr.searchsorted ([0, 1], side='right') Out[209]: array ([3, 7])

再来看 searchsorted 的另一个用法，假设我们有一个数值数组（其中的值在 0 到 10000 之间），还有一个表示“分箱边界”的数组，我们希望用它将数值数组拆分开：

data = np.floor (rng.uniform (0, 10000, size=50))

bins = np.array ([0, 100, 1000, 5000, 10000])

data Out[212]:

array ([ 815. , 1598. , 3401. , 4651. , 2664. , 8157. , 1932. , 1294. , 916. , 5985. , 8547. , 6016. , 9319. , 7247. , 8605. , 9293. , 5461. , 9376. , 4949. , 2737. , 4517. , 6650. , 3308. , 9034. , 2570. , 3398. , 2588. , 3554. , 50. , 6286. , 2823. , 680. , 6168. , 1763. , 3043. , 4408. , 1502. , 2179. , 4743. , 4763. , 2552. , 2975. , 2790. , 2605. , 4827. , 2119. , 4956. , 2462. , 8384. , 1801. ])

为了得到各数据点所属区间的编号（其中 1 表示分箱[0，100）），我们可以直接使用 searchsorted:

labels = bins.searchsorted (data)

labels

Out[214]:

array ([2, 3, 3, 3, 3, 4, 3, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 1, 4, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],

再结合 pandas 的 groupby 方法，就可以轻松地对原数据集进行分箱：

pd.Series (data). groupby (labels). mean () Out[215]: 1 50.000000 2 803.666667 3 3079.741935 4 7635.200000 dtype: float 64

# A.7 使用 Numba 编写快速 NumPy 函数

Numba（http://numba.pydata.org）是一个开源项目，它可以利用 CPU、GPU 或其他硬件为 NumPy 类型数据创建快速函数。它使用了 LLVM 项目（http://llvm.org/），将 Python 代码编译为机器代码。

为了介绍 Numba，先考虑一个纯 Python 函数，它使用 for 循环计算表达式（x- y）. mean ():

import numpy as np def mean_distance (x, y): nx  $\equiv$  len (x) result  $= 0.0$  count  $= 0$  for i in range (nx): result  $+ = x[i]$  - y[i] count  $+ = 1$  return result / count

# 这个函数很慢：

x = rng. standard_normal (10_000_000)  y = rng. standard_normal (10_000_000)  %timeit mean_distance (x, y)  1 loop, best of 3: 2 s per loop  %timeit (x - y). mean ()  100 loops, best of 3: 14.7 ms per loop

NumPy 的版本要比它快 100 倍，使用 numpyjit 函数，我们可以将这个函数编译为 Numba 函数：

import numba as nb  numba_mean_distance = nb.jit (mean_distance)

# 也可以写成装饰器的形式：

@nb. jit def numba_mean_distance (x, y): nx  $\equiv$  len (x) result  $= 0.0$  count  $= 0$  for i in range (nx): result  $+ = x[i]$  - y[i] count  $+ = 1$  return result / count

# 这个函数要比向量化的 NumPy 更快：

%timeit numba_mean_distance (x, y)  100 loops, best of 3: 10.3 ms per loop

Numba 不能编译所有的纯 Python 代码，但它支持 Python 中的一类重要代码，即最有用的数值算法。

Numba 是一个功能强大的库，支持多种硬件、编译模式和用户扩展。它还可以编译 NumPy Python API 的一个实质性子集，而不使用 for 循环。Numba 也可以识别可以编译为机器编码的结构体，但是若替换调用为 CPython API，它就不知道如何编译了。Numba 的 jit 函数有一个选项 nopython=True，用于将代码限制为特定的 Python 代码，后者无须调用任何 Python C API 就可以编译为 LLVM。jit（nopython=True）有一个简短的别名 numba. njit。前面的示例还可以这样写：

前面的示例还可以这样写：

from numba import float 64, njit @njit (float 64 (float 64[:,], float 64[:])) def mean_distance (x, y): return (x- y). mean ()

如果想学习更多内容，建议读者阅读 Numba 的线上文档（http://numba.pydata.org/）。下一节介绍一个创建自定义 Numpy ufunc 对象的示例。

# 使用 Numba 创建自定义 numpy. ufunc 对象

numba. vectorize 函数可以创建编译的 NumPy ufunc，其功能与内置的 ufunc 相似。考虑一个 numpy. add 的 Python 实现：

from numba import vectorize @vectorize def nb_add (x, y): return x + y

# 可以得到：

x = np.arange (10) nb_add (x, x) Out[14]: array ([ 0. , 2. , 4. , 6. , 8. , 10. , 12. , 14. , 16. , 18. ]） nb_add.acccumulate (x, 0) Out[15]: array ([ 0. , 1. , 3. , 6. , 10. , 15. , 21. , 28. , 36. , 45. ]）

# A.8 高阶数组的输入和输出

在第 4 章中，我们熟悉了 np. save 和 np. load，它们可用于在磁盘上以二进制格式存储数组。其实还有其他一些选项可用于更复杂的场景。尤其是内存映射，它使你能对不适合在内存中存储的数据集完成特定操作。

# A.8.1 内存映射文件

内存映射文件是一种将磁盘上的二进制数据文件当作内存中存储的数组进行处理的方式。NumPy 实现了一个类似于 ndarray 的 memmap 对象，它允许将大文件分成小段进行读写，无须将整个数组

读入内存。另外，memmap 也拥有与内存中数组同样的方法，因此许多能用于 ndarray 的算法也能用于 memmap。

要创建一个新内存映射，可以使用函数 np. memmap 并传入文件路径、数据类型、形状以及文件模式：

mmap = np.memmap ('mymmap', dtype='float 64', node='w+', shape=(10000, 10000))

mmapOut[218]: memmap ([[0. , 0. , 0. , ..., 0. , 0. , 0. ],

$$
\begin{array}{rl} & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right],}\\ & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right],}\\ & {\ldots ,}\\ & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right],}\\ & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right],}\\ & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right],}\\ & {\left[0., 0., 0.,\ldots ,0., 0., 0.\right])} \end{array}
$$

对 memmap 进行切片将会返回磁盘上数据的视图：

section = mmap[: 5]

如果将数据赋值给这些视图，数据会先在内存中进行缓存，这意味着如果是在另一个应用中读取文件，视图的变动不会立即反映到磁盘文件上。调用 flush 即可将修改同步到磁盘中：

section[:] = rng. standard_normal ((5, 10000)) mmap.flush () mmapOut[222]: memmap ([[- 0.9074, - 1.0954, 0.0071, ..., 0.2753, - 1.1641, 0.8521], [- 0.0103, - 0.0640, - 1.0615, ..., - 1.1003, 0.2505, 0.5832], [0.4583, 1.2992, 1.7137, ..., 0.8691, - 0.7889, - 0.2431], ..., [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. \|- 0.9074, - 1.0954, 0.0071, ..., 0.2753, - 1.1641, 0.8521], [- 0.0103, - 0.0640, - 1.0615, ..., - 1.1003, 0.2505, 0.5832], [0.4583, 1.2992, 1.7137, ..., 0.8691, - 0.7889, - 0.2431], ..., [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ]]) del mmap

del mmap

每当内存映射超出了范围，它就会被垃圾回收器回收，之前对其所做的任何修改都会刷新到磁盘。当打开一个已经存在的内存映射时，仍然需要指定数据类型和形状，这是因为磁盘上的文件只是一块二进制数据而已，缺少数据类型信息、形状和步长：

mmap = np.memmap ('mymmap', dtype='float 64', shape=(10000, 10000))

mmap

Out[225]:

mmap（[- 0.9074，- 1.0954，0.0071，.，0.2753，- 1.1641，0.8521]，[- 0.0103，- 0.0646，- 1.0615，- 1.1003，0.2505，0.5832]，[0.4583，1.2992，1.7137，，0.8691，- 0.7889，- 0.2431]，[0. ，0. ，0. ，.，0. ，0. ，0. ]，[0. ，0. ，0. ，.，0. ，0. ，0. ]，[0. ，0. ，0. ，.，0. ，0. ，0. ]])

内存映射也可以结合A.5 节中介绍的结构化数组或嵌套数据类型使用。

如果你是在自己的计算机上运行这个示例，可能希望删除我们在前面创建的大文件：

%xdel mmap!rm mymmap

# A.8.2 HDF 5 及其他数组存储方式

A.8.2 HDF 5 及其他数组存储方式 PyTables 和 h 5 py 这两个 Python 项目提供了适用于 NumPy 的接口，可以将数组数据存储为高效并可压缩的 HDF 5 格式（HDF 的意思是“分层数据格式”）。你可以安全地将几百 GB 甚至 TB 级的数据存储为 HDF 5 格式。要学习 Python 使用 HDF 5 的更多内容，请参考 pandas 线上文档（http://pandas.pydata.org）。

# A.9 性能技巧

使用 NumPy 的代码性能一般都很不错，因为数组运算一般都比纯 Python 循环快得多。下面列出了一些建议，可以最大限度地提高性能：

·将 Python 循环和条件逻辑转换为数组运算和布尔数组运算。

·尽量使用广播。

·使用数组视图（即切片）以避免复制数据。

·利用 ufunc 及其方法。

·利用 ufunc 及其方法。如果单纯用 NumPy 达不到所需的性能，可以考虑使用 C、Fortran 或 Cython 来编写代码。我在工作中经常用到 Cython（http://cpython.org），因为它不用花费太多精力就能达到 C 语言的性能。

# 连续内存的重要性

连续内存的重要性虽然这个话题有点超出本书的范围，但还是要提一下，因为在某些应用场景中，数组的内存排布会对计算速度造成极大的影响。这是因为性能差异在一定程度上与 CPU 的缓存层级有关。运算过程中访问连续内存块（例如，对以 C 顺序存储的数组的行求和）一般是最快的，这是因为内存子系统会

将适当的内存块缓存到 CPU 的低延迟 L 1 或 L 2 缓存中。此外，NumPy 的 C 代码库的特定代码路径对连续运算场景进行了优化处理，这样就能避免原生的步进式内存访问。

数组的内存排布是连续的，是指元素是以它们在数组中出现的顺序[即 Fortran 型（列优先）或 C 型（行优先）]存储在内存中的。默认情况下，NumPy 数组是以 C 型连续的方式创建的。列优先的数组（比如 C 型连续数组的转置）也称为 Fortran 型连续。通过 ndarray 的 flags 属性即可查看这些信息：

arr_c = np.ones ((100, 10000), order='C')  arr_f = np.ones ((100, 10000), order='F')  arr_c.flags  Out[230]:      C_CONTIGUOUS : True      F_CONTIGUOUS : False      OwNDATA : True      WRITEABLE : True      ALIGNED : True      WRITEBACKIFCOPY : False      UPDATEIFCOPY : False  arr_f.flags  Out[231]:      C_CONTIGUOUS : False      F_CONTIGUOUS : True      OwNDATA : True      WRITEABLE : True      ALIGNED : True      WRITEBACKIFCOPY : False      UPDATEIFCOPY : False  arr_f.flags. f_contiguous  Out[232]: True

在这个例子中，对两个数组的行进行求和计算，从理论上说 arr_c 会比 arr_f 快，这是因为 arr_c 的行在内存中是连续的。我们可以在 IPython 中用%timeit 来检验一下（每个人的计算机不同，结果也会不同）：

%timeit arr_c.sum (1)  444 us +- 60.5 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)  %timeit arr_f.sum (1)  581 us +- 8.16 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)

如果想从 NumPy 压榨出更多性能，通常这里就是下功夫的地方。如果数组不具备适当的内存顺序，可以使用 copy 并传入'C'或'F'来解决该问题：

arr_f.copy ('C'). flags

# Out[235]:

C_CONTIGUOUS : True  F_CONTIGUOUS : False  Owndata : True  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False

注意，在构造数组的视图时，其结果不一定是连续的：

arr_c[: 50]. flags. contiguous  Out[236]: True

arr_c[:, : 50]. flags  Out[237]:  C_CONTIGUOUS : False  F_CONTIGUOUS : False  Owndata : False  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False
